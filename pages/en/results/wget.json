{
  "id": "msg_01Gzm9jSUUoCLP1mVW2pshhG",
  "content": [
    {
      "text": "# wget command\n\nDownload files from the web via HTTP, HTTPS, and FTP protocols.\n\n## Overview\n\n`wget` is a non-interactive command-line utility for downloading files from the web. It supports HTTP, HTTPS, and FTP protocols, and can work in the background, resume interrupted downloads, and follow links within websites. It's particularly useful for batch downloading, mirroring websites, or retrieving files in scripts.\n\n## Options\n\n### **-O, --output-document=FILE**\n\nWrite documents to FILE instead of creating files based on remote names.\n\n```console\n$ wget -O latest-linux.iso https://example.com/downloads/linux.iso\n--2025-05-05 10:15:32--  https://example.com/downloads/linux.iso\nResolving example.com... 93.184.216.34\nConnecting to example.com|93.184.216.34|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1073741824 (1.0G) [application/octet-stream]\nSaving to: 'latest-linux.iso'\n\nlatest-linux.iso    100%[===================>]   1.00G  5.25MB/s    in 3m 15s  \n\n2025-05-05 10:18:47 (5.25 MB/s) - 'latest-linux.iso' saved [1073741824/1073741824]\n```\n\n### **-c, --continue**\n\nResume getting a partially-downloaded file.\n\n```console\n$ wget -c https://example.com/large-file.zip\n--2025-05-05 10:20:12--  https://example.com/large-file.zip\nResolving example.com... 93.184.216.34\nConnecting to example.com|93.184.216.34|:443... connected.\nHTTP request sent, awaiting response... 206 Partial Content\nLength: 104857600 (100M), 52428800 (50M) remaining [application/zip]\nSaving to: 'large-file.zip'\n\nlarge-file.zip      50%[======>           ]  50.00M  3.15MB/s    in 16s     \n\n2025-05-05 10:20:28 (3.15 MB/s) - 'large-file.zip' saved [104857600/104857600]\n```\n\n### **-b, --background**\n\nGo to background immediately after startup.\n\n```console\n$ wget -b https://example.com/huge-archive.tar.gz\nContinuing in background, pid 1234.\nOutput will be written to 'wget-log'.\n```\n\n### **-r, --recursive**\n\nTurn on recursive retrieving (download entire website directories).\n\n```console\n$ wget -r -np https://example.com/docs/\n--2025-05-05 10:25:45--  https://example.com/docs/\nResolving example.com... 93.184.216.34\nConnecting to example.com|93.184.216.34|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 8192 (8.0K) [text/html]\nSaving to: 'example.com/docs/index.html'\n\nexample.com/docs/index.html    100%[===================>]   8.00K  --.-KB/s    in 0.1s    \n\n2025-05-05 10:25:46 (80.0 KB/s) - 'example.com/docs/index.html' saved [8192/8192]\n\n... [more files downloaded] ...\n```\n\n### **-np, --no-parent**\n\nDo not ascend to the parent directory when retrieving recursively.\n\n```console\n$ wget -r -np https://example.com/docs/\n```\n\n### **-m, --mirror**\n\nTurn on options suitable for mirroring: recursive, time-stamping, infinite recursion depth, and preserve FTP directory listings.\n\n```console\n$ wget -m https://example.com/blog/\n--2025-05-05 10:30:12--  https://example.com/blog/\nResolving example.com... 93.184.216.34\nConnecting to example.com|93.184.216.34|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 16384 (16K) [text/html]\nSaving to: 'example.com/blog/index.html'\n\nexample.com/blog/index.html    100%[===================>]  16.00K  --.-KB/s    in 0.1s    \n\n2025-05-05 10:30:13 (160.0 KB/s) - 'example.com/blog/index.html' saved [16384/16384]\n\n... [more files downloaded] ...\n```\n\n### **-q, --quiet**\n\nQuiet mode (no output).\n\n```console\n$ wget -q https://example.com/file.txt\n```\n\n### **-P, --directory-prefix=PREFIX**\n\nSave files to PREFIX/...\n\n```console\n$ wget -P downloads/ https://example.com/file.txt\n--2025-05-05 10:35:22--  https://example.com/file.txt\nResolving example.com... 93.184.216.34\nConnecting to example.com|93.184.216.34|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1024 (1.0K) [text/plain]\nSaving to: 'downloads/file.txt'\n\ndownloads/file.txt   100%[===================>]   1.00K  --.-KB/s    in 0.1s    \n\n2025-05-05 10:35:23 (10.0 KB/s) - 'downloads/file.txt' saved [1024/1024]\n```\n\n### **--limit-rate=RATE**\n\nLimit download rate to RATE (e.g., 200k for 200 KB/s).\n\n```console\n$ wget --limit-rate=200k https://example.com/large-file.zip\n--2025-05-05 10:40:15--  https://example.com/large-file.zip\nResolving example.com... 93.184.216.34\nConnecting to example.com|93.184.216.34|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 104857600 (100M) [application/zip]\nSaving to: 'large-file.zip'\n\nlarge-file.zip      100%[===================>] 100.00M  200KB/s    in 8m 20s  \n\n2025-05-05 10:48:35 (200 KB/s) - 'large-file.zip' saved [104857600/104857600]\n```\n\n## Usage Examples\n\n### Downloading a file with a progress bar\n\n```console\n$ wget https://example.com/file.txt\n--2025-05-05 10:50:12--  https://example.com/file.txt\nResolving example.com... 93.184.216.34\nConnecting to example.com|93.184.216.34|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1024 (1.0K) [text/plain]\nSaving to: 'file.txt'\n\nfile.txt             100%[===================>]   1.00K  --.-KB/s    in 0.1s    \n\n2025-05-05 10:50:13 (10.0 KB/s) - 'file.txt' saved [1024/1024]\n```\n\n### Mirroring a website with depth limit\n\n```console\n$ wget -m -k -p -l 2 https://example.com/\n```\n\nThis command mirrors the website, converts links for offline viewing (-k), downloads necessary page requisites (-p), and limits the recursion depth to 2 levels (-l 2).\n\n### Downloading files from a password-protected site\n\n```console\n$ wget --user=username --password=password https://example.com/protected/file.pdf\n```\n\n### Downloading multiple files listed in a text file\n\n```console\n$ cat urls.txt\nhttps://example.com/file1.txt\nhttps://example.com/file2.txt\nhttps://example.com/file3.txt\n\n$ wget -i urls.txt\n```\n\n## Tips:\n\n### Resume Interrupted Downloads\n\nIf your download gets interrupted, use `wget -c URL` to resume from where it left off instead of starting over.\n\n### Download in the Background\n\nFor large downloads, use `wget -b URL` to run wget in the background. Output will be written to wget-log in the current directory.\n\n### Limit Bandwidth Usage\n\nUse `--limit-rate=RATE` (e.g., `--limit-rate=200k`) to avoid consuming all available bandwidth, especially useful on shared connections.\n\n### Mirror a Website for Offline Viewing\n\nUse `wget -m -k -p website-url` to create a complete offline copy with working links. The `-k` option converts links for local viewing.\n\n### Use a Different User Agent\n\nSome websites block wget. Use `--user-agent=\"Mozilla/5.0\"` to identify as a browser instead.\n\n## Frequently Asked Questions\n\n#### Q1. How do I download a file and save it with a different name?\nA. Use `wget -O filename URL` to save the downloaded file with a custom name.\n\n#### Q2. How can I download files from a password-protected site?\nA. Use `wget --user=username --password=password URL` to provide authentication credentials.\n\n#### Q3. How do I download an entire website?\nA. Use `wget -m -k -p website-url` to mirror the site with proper link conversion for offline viewing.\n\n#### Q4. How can I limit the download speed?\nA. Use `wget --limit-rate=RATE URL` (e.g., `--limit-rate=200k` for 200 KB/s).\n\n#### Q5. How do I resume a partially downloaded file?\nA. Use `wget -c URL` to continue downloading from where it was interrupted.\n\n## References\n\nhttps://www.gnu.org/software/wget/manual/wget.html\n\n## Revisions\n\n- 2025/05/05 First revision",
      "type": "text"
    }
  ],
  "model": "claude-3-7-sonnet-20250219",
  "role": "assistant",
  "stop_reason": "end_turn",
  "stop_sequence": null,
  "type": "message",
  "usage": {
    "cache_creation_input_tokens": 0,
    "cache_read_input_tokens": 0,
    "input_tokens": 1678,
    "output_tokens": 2490
  }
}